{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b5c05a7",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32949751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFE, SelectKBest, chi2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score ,classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8b76f7",
   "metadata": {},
   "source": [
    "# Load and Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b8257db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (242, 15)\n",
      "Testing set  size: (61, 15)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"heart_diseases_final.csv\")  \n",
    "\n",
    "# Feaatures & target\n",
    "X = df.drop(columns=['target'])\n",
    "y = df['target']\n",
    "\n",
    "# Dataset split into 80% training and 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(\"Training set size:\", X_train.shape)\n",
    "print(\"Testing set  size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b134709b",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning by using:\n",
    "* GridSearchCV\n",
    "* RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "907b219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pipelines for each model\n",
    "pipelines = {\n",
    "    \"logistic\": Pipeline([\n",
    "        (\"clf\", LogisticRegression(max_iter=1000, random_state=42))\n",
    "    ]),\n",
    "    \"svm\": Pipeline([\n",
    "        (\"clf\", SVC(probability=True, random_state=42))\n",
    "    ])\n",
    "}\n",
    "\n",
    "\n",
    "# Define hyperparameter grids\n",
    "param_grids = {\n",
    "    \"logistic\": {\n",
    "        \"clf__C\": [0.001, 0.01, 0.1, 1, 5, 10, 50, 100],\n",
    "        \"clf__penalty\": [\"l2\"],\n",
    "        \"clf__solver\": [\"lbfgs\"]\n",
    "    },\n",
    "    \"svm\": {\n",
    "        'clf__C': [0.001, 0.01, 0.1, 1, 5, 10, 50],\n",
    "        \"clf__kernel\": [\"linear\", \"rbf\", \"poly\"],\n",
    "        \"clf__gamma\": [\"scale\", \"auto\", 0.01, 0.1, 1]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c78cd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuning LOGISTIC...\n",
      "Best params (GridSearch): {'clf__C': 1, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}\n",
      "Best CV accuracy (GridSearch): 0.8594\n",
      "Best params (RandomizedSearch): {'clf__solver': 'lbfgs', 'clf__penalty': 'l2', 'clf__C': 10}\n",
      "Best CV accuracy (RandomizedSearch): 0.8552\n",
      "\n",
      "Tuned Model Test Set Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.82      0.89        33\n",
      "           1       0.82      0.96      0.89        28\n",
      "\n",
      "    accuracy                           0.89        61\n",
      "   macro avg       0.89      0.89      0.89        61\n",
      "weighted avg       0.90      0.89      0.89        61\n",
      "\n",
      "\n",
      "LOGISTIC comparison:\n",
      "Baseline Accuracy: 0.8852\n",
      "Tuned Accuracy   : 0.8852\n",
      "\n",
      "Tuning SVM...\n",
      "Best params (GridSearch): {'clf__C': 5, 'clf__gamma': 'scale', 'clf__kernel': 'linear'}\n",
      "Best CV accuracy (GridSearch): 0.8426\n",
      "Best params (RandomizedSearch): {'clf__kernel': 'linear', 'clf__gamma': 'scale', 'clf__C': 1}\n",
      "Best CV accuracy (RandomizedSearch): 0.8302\n",
      "\n",
      "Tuned Model Test Set Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.85      0.89        33\n",
      "           1       0.84      0.93      0.88        28\n",
      "\n",
      "    accuracy                           0.89        61\n",
      "   macro avg       0.89      0.89      0.89        61\n",
      "weighted avg       0.89      0.89      0.89        61\n",
      "\n",
      "\n",
      "SVM comparison:\n",
      "Baseline Accuracy: 0.9180\n",
      "Tuned Accuracy   : 0.8852\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store best models info\n",
    "best_models = {}\n",
    "\n",
    "for model_name in pipelines.keys():\n",
    "    print(f\"\\nTuning {model_name.upper()}...\")\n",
    "    # Hyperparameter Tuning\n",
    "    pipeline = pipelines[model_name]\n",
    "    param_grid = param_grids[model_name]\n",
    "\n",
    "    # GridSearchCV\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(f\"Best params (GridSearch): {grid_search.best_params_}\")\n",
    "    print(f\"Best CV accuracy (GridSearch): {grid_search.best_score_:.4f}\")\n",
    "\n",
    "    # RandomizedSearchCV\n",
    "    randomized_search = RandomizedSearchCV(\n",
    "        pipeline, param_grid, n_iter=5, cv=5, scoring='accuracy', n_jobs=-1, random_state=42\n",
    "    )\n",
    "    randomized_search.fit(X_train, y_train)\n",
    "    print(f\"Best params (RandomizedSearch): {randomized_search.best_params_}\")\n",
    "    print(f\"Best CV accuracy (RandomizedSearch): {randomized_search.best_score_:.4f}\")\n",
    "\n",
    "    # Evaluate tuned model on test set\n",
    "    tuned_model = grid_search.best_estimator_  # using GridSearchCV result\n",
    "    tuned_pred = tuned_model.predict(X_test)\n",
    "    tuned_acc = accuracy_score(y_test, tuned_pred)\n",
    "    print(\"\\nTuned Model Test Set Evaluation:\")\n",
    "    print(classification_report(y_test, tuned_pred))\n",
    "\n",
    "    # Evaluate baseline mode;\n",
    "    baseline_pipeline = pipeline.fit(X_train, y_train)\n",
    "    baseline_pred = baseline_pipeline.predict(X_test)\n",
    "    baseline_acc = accuracy_score(y_test, baseline_pred)\n",
    "\n",
    "    # Compare baseline vs tuned\n",
    "    print(f\"\\n{model_name.upper()} comparison:\")\n",
    "    print(f\"Baseline Accuracy: {baseline_acc:.4f}\")\n",
    "    print(f\"Tuned Accuracy   : {tuned_acc:.4f}\")\n",
    "\n",
    "    # Decide which model to save\n",
    "    if tuned_acc >= baseline_acc:\n",
    "        best_model_to_save = tuned_model\n",
    "    else:\n",
    "        best_model_to_save = baseline_pipeline\n",
    "\n",
    "    # Store best model info\n",
    "    best_models[model_name] = {\n",
    "        \"baseline_accuracy\": baseline_acc,\n",
    "        \"tuned_accuracy\": tuned_acc,\n",
    "        \"saved_model\": best_model_to_save\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1dfddd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Summary of Best Models to be Saved =====\n",
      "LOGISTIC: Best Accuracy = 0.8852\n",
      "SVM: Best Accuracy = 0.9180\n"
     ]
    }
   ],
   "source": [
    "# Summary of best models\n",
    "print(\"\\n===== Summary of Best Models to be Saved =====\")\n",
    "for model_name, info in best_models.items():\n",
    "    best_acc = max(info['baseline_accuracy'], info['tuned_accuracy'])\n",
    "    print(f\"{model_name.upper()}: Best Accuracy = {best_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6820aa7",
   "metadata": {},
   "source": [
    "# Model Pipeline Export\n",
    "1. Save the trained model using joblib or pickle (.pkl format).\n",
    "2. Ensure reproducibility by saving model pipeline (preprocessing + model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09bffe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raw dataset\n",
    "df = pd.read_csv(\"heart_diseases.csv\")\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=['num'])\n",
    "y = df['num'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Define features\n",
    "categ_cols = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'thal']\n",
    "num_cols = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'ca']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b612fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing Pipeline\n",
    "numeric_transf = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "catego_transf = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encode\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"numerical\", numeric_transf, num_cols),\n",
    "    (\"categorical\", catego_transf, categ_cols)\n",
    "])\n",
    "\n",
    "# --- Custom Feature Selector ---\n",
    "class RFEChi2Union(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, rfe_k=10, chi2_k=10, random_state=42):\n",
    "        self.rfe_k = rfe_k\n",
    "        self.chi2_k = chi2_k\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Use feature indices instead of column names\n",
    "        n_features = X.shape[1]\n",
    "        feature_names = np.arange(n_features)\n",
    "\n",
    "        # RFE with RandomForest\n",
    "        rf = RandomForestClassifier(n_estimators=100, random_state=self.random_state)\n",
    "        rfe = RFE(estimator=rf, n_features_to_select=self.rfe_k, step=1)\n",
    "        rfe.fit(X, y)\n",
    "        self.rfe_features_ = feature_names[rfe.support_]\n",
    "\n",
    "        # Chi^2\n",
    "        scaler = MinMaxScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "        chi2_selector = SelectKBest(score_func=chi2, k=min(self.chi2_k, n_features))\n",
    "        chi2_selector.fit(X_scaled, y)\n",
    "        self.chi2_features_ = feature_names[chi2_selector.get_support()]\n",
    "\n",
    "        # Final feature set (indices)\n",
    "        self.selected_features_ = np.unique(np.concatenate([self.rfe_features_, self.chi2_features_]))\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[:, self.selected_features_]\n",
    "\n",
    "# Build final pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"feature_selection\", RFEChi2Union(rfe_k=10, chi2_k=10)),\n",
    "    (\"model\", SVC(probability=True, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b92b5def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8842975206611571\n",
      "Test Accuracy: 0.9016393442622951\n",
      "✅Final pipeline (preprocessing + PCA + Feature Selection + Best model(SVM)) saved as svm_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Train\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Train Accuracy:\", pipeline.score(X_train, y_train))\n",
    "print(\"Test Accuracy:\", pipeline.score(X_test, y_test))\n",
    "\n",
    "# Save full pipeline\n",
    "joblib.dump(pipeline, \"svm_model.pkl\")\n",
    "print(\"✅Final pipeline (preprocessing + PCA + Feature Selection + Best model(SVM)) saved as svm_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4993bde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄Results saved to model_results.txt\n"
     ]
    }
   ],
   "source": [
    "# Predictions\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "report = classification_report(y_test, y_pred, digits=4)\n",
    "\n",
    "# Save report to txt\n",
    "with open(\"model_results.txt\", \"w\") as f:\n",
    "    f.write(\"Model Evaluation Results\\n\")\n",
    "    f.write(\"========================\\n\")\n",
    "    f.write(f\"Accuracy: {accuracy:.4f}\\n\")\n",
    "    f.write(f\"Precision: {precision:.4f}\\n\")\n",
    "    f.write(f\"Recall: {recall:.4f}\\n\")\n",
    "    f.write(f\"F1-score: {f1:.4f}\\n\")\n",
    "    f.write(f\"ROC-AUC: {auc:.4f}\\n\\n\")\n",
    "    f.write(\"Classification Report:\\n\")\n",
    "    f.write(report)\n",
    "\n",
    "print(\"📄Results saved to model_results.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3874f10f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
